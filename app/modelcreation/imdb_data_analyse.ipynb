{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse IMDB Movie Data for Title Segmentation & Reccomendation\n",
    "[blog title](blog link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "sdjafkldsjfkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "dfjakdslfjdskl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import requests\n",
    "import io\n",
    "import gzip\n",
    "import mxnet as mx\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import PCA\n",
    "from sagemaker import KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Load the basic title info, alternate title info and title rating info into data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remoteImdbToDf(dataset):\n",
    "    url=\"https://datasets.imdbws.com/\" + dataset + \".tsv.gz\"\n",
    "    content=requests.get(url).content\n",
    "    open(dataset + '.tsv.gz', 'wb').write(content)\n",
    "    \n",
    "    with gzip.open(dataset + '.tsv.gz', 'rb') as read_file:\n",
    "        file_content = read_file.read()\n",
    "        write_file = open(dataset + '.tsv', 'wb')\n",
    "        write_file.write(file_content)\n",
    "        write_file.close()\n",
    "    \n",
    "    return pd.read_csv(dataset + '.tsv', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titleakas = remoteImdbToDf('title.akas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titlebasics = remoteImdbToDf('title.basics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titleratings = remoteImdbToDf('title.ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis EDA – Data cleaning and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titlebasics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the column names lower case to make it easier to work with\n",
    "df_titlebasics.columns = ['titleid','type','title','originaltitle','isadult','startyear','endyear','length','genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titlebasics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're probably only going to want titles that are movies for the recommendation, let's check this field does that\n",
    "df_titlebasics[df_titlebasics['type']=='movie'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the column names lower case to make it easier to work with\n",
    "df_titleakas.columns = ['titleid','ordering','title','region','language','types','attributes','isoriginaltitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titleakas.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the basic and alternate info data frames on the title id field\n",
    "df_titlesfull = pd.merge(left=df_titlebasics, right=df_titleakas, left_on='titleid', right_on='titleid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need this data anymore, all required info is in the new data frame\n",
    "del df_titlebasics\n",
    "del df_titleakas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titlesfull.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titleratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the column names lower case to make it easier to work with\n",
    "df_titleratings.columns = ['titleid', 'averagerating', 'numvotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_titleratings['averagerating'], edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titleratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the title info and ratings data frames on the title id field\n",
    "df_titles = pd.merge(left=df_titlesfull, right=df_titleratings, left_on='titleid', right_on='titleid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need this data anymore, all required info is in the new data frame\n",
    "del df_titleratings\n",
    "del df_titlesfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the titles get duplicated if it's moved language/region, etc. Let's only consider original titles to remove bias\n",
    "df_titles = df_titles.drop_duplicates(subset=['titleid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's get only movies\n",
    "df_titles = df_titles[df_titles['type']=='movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop some of the columns that won't contribute much to the clustering\n",
    "#  (reconsider region later if needed, obviously need to one-hot-encode it and remove \\N values)\n",
    "df_titles.drop(['originaltitle','ordering','title_y','type',\n",
    "                'types','region','types','attributes',\n",
    "                'isoriginaltitle','endyear'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the column names lower case to make it easier to work with, rename some columns due to merge naming\n",
    "df_titles.columns = ['titleid', 'title', 'isadult',\n",
    "                     'year','length','genres',\n",
    "                     'language','averagerating',\n",
    "                     'numvotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's not consider any titles that don't have a valid year value\n",
    "df_titles = df_titles[(df_titles['year']!='\\\\N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  convert the year value (string) to integer for easy scaling and comparison\n",
    "df_titles['year'] = df_titles['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_titles.year.unique(),\n",
    "        df_titles.year.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "sns.scatterplot(x = df_titles['numvotes'], y = df_titles['averagerating'])\n",
    "plt.xlabel('number of votes')\n",
    "plt.ylabel('average rating of movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "sns.scatterplot(x = df_titles['year'], y = df_titles['numvotes'])\n",
    "plt.ylabel('number of votes')\n",
    "plt.xlabel('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'genres' column contains non-numerical comma-separated-values for zero, one or multiple genres for the title. To make this value comparible (and useful for clustering), this needs to be made into a numerical (0 or 1) for each value. To do this, we need to use a process called 'one-hot-encoding' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.genres.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's convert the csv column to a pandas list object in a new column\n",
    "df_titles['genres_list'] = df_titles.genres.str.split(',').tolist()\n",
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the one hot encoded values for genre. \n",
    "# (this table is relatively sparse)\n",
    "genres_one_hot_encoded = df_titles.genres_list.str.join('|').str.get_dummies().add_prefix('genre_')\n",
    "genres_one_hot_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add these new columns to the original full data\n",
    "df_titles = pd.concat([df_titles, genres_one_hot_encoded], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the one hot encoded values for language. \n",
    "language_one_hot_encoded = pd.get_dummies(df_titles.language, prefix='language')\n",
    "language_one_hot_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add these new columns to the original full data\n",
    "df_titles = pd.concat([df_titles, language_one_hot_encoded], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can drop the descriptive value columns, and the one-hot-encoded columns for null values\n",
    "df_titles.drop(['genres','language','genres_list','genre_\\\\N','language_\\\\N'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.titleid.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.titleid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.title.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now set the ‘titleid and title’ \n",
    "#   as the index and the rest of the numerical \n",
    "#   features become the attributes of each unique title.\n",
    "df_titles.index=df_titles['titleid'] + \" \" + df_titles['title']\n",
    "df_titles.drop(['titleid','title'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of titles where the length value isn't available\n",
    "df_titles = df_titles[df_titles['length'] != '\\\\N']\n",
    "\n",
    "# and conver the length to integer for scale/comparison ease\n",
    "df_titles['length'] = df_titles['length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some really short/long titles, lowly rated, and old movies\n",
    "df_titles = df_titles[\n",
    "    (df_titles['length'] > 30) & \n",
    "    (df_titles['length'] < 360) &  \n",
    "    (df_titles['numvotes'] > 50000) &\n",
    "    (df_titles['year'] > 1970) &\n",
    "    (df_titles['averagerating'] > 6.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling – We need to standardize the scaling of the numerical columns \n",
    "#   in order to use any distance based analytical methods so that we can \n",
    "#   compare the relative distances between different feature columns. We can \n",
    "#   use minmaxscaler to transform the numerical columns so that they also \n",
    "#   fall between 0 and 1.\n",
    "scaler=MinMaxScaler()\n",
    "df_titles_scaled=pd.DataFrame(scaler.fit_transform(df_titles))\n",
    "df_titles_scaled.columns=df_titles.columns\n",
    "df_titles_scaled.index=df_titles.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current service/execution role (ensure it has Sagemaker execute permissions)\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this value if you need\n",
    "bucket_name='simontest-2020-10-24'\n",
    "num_components=95\n",
    "\n",
    "pca_SM = PCA(role=role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type='ml.c4.xlarge',\n",
    "          output_path='s3://'+ bucket_name +'/titles/',\n",
    "            num_components=num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_titles_scaled.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca_SM.fit(pca_SM.record_set(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=pca_SM._current_job_name\n",
    "model_key = \"titles/\" + job_name + \"/output/model.tar.gz\"\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())\n",
    "v=pd.DataFrame(pca_model_params['v'].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[75:,:].apply(lambda x: x*x).sum()/s.apply(lambda x: x*x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_20=s.iloc[75:,:]\n",
    "v_20=v.iloc[:,75:]\n",
    "v_20.columns=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\n",
    "             15,16,17,18,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_num=18\n",
    "\n",
    "first_comp = v_20[20-component_num]\n",
    "comps = pd.DataFrame(list(zip(first_comp, df_titles_scaled.columns)), columns=['weights', 'features'])\n",
    "comps['abs_weights']=comps['weights'].apply(lambda x: np.abs(x))\n",
    "ax=sns.barplot(data=comps.sort_values('abs_weights', ascending=False).head(10), x=\"weights\", y=\"features\", palette=\"Blues_d\")\n",
    "ax.set_title(\"PCA Component Makeup: #\" + str(component_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will need to review this as the data will change over time\n",
    "PCA_list=['Romance/Drama', 'Crime/Action/Thriller', 'Adventure/Drama', 'Horror/Thriller',\n",
    "          'Action/Romance', 'Sci-Fi/Horror/Mystery', 'Sci-Fi/Mistery', 'Romance/Mystery/Crime', 'Mystery/Drama/Comedy',\n",
    "          'Sci-Fi/Fantasy', 'EN-Lang/Mystery/Fantasy', 'Foreign/Older/Mystery', 'Recent/Bio/Adventure', \n",
    "          'Older/EN-Lang/Adventure', 'Popular/Fantasy/Animation', 'Older/Bio/Animation', 'TR-Lang/Popular/Recent',\n",
    "          'FR-Lang/Popular', 'JA-Lang/Music/Sport', 'JA-Lang/FR-Lang/Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca_predictor = pca_SM.deploy(initial_instance_count=1, \n",
    "                                 instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = pca_predictor.predict(train_data)\n",
    "df_titles_transformed=pd.DataFrame()\n",
    "for a in result:\n",
    "    b=a.label['projection'].float32_tensor.values\n",
    "    df_titles_transformed=df_titles_transformed.append([list(b)])\n",
    "df_titles_transformed.index=df_titles_scaled.index\n",
    "df_titles_transformed=df_titles_transformed.iloc[:,75:]\n",
    "df_titles_transformed.columns=PCA_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_titles_transformed.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the number of clusters is high, hopefully we get better recommendations\n",
    "num_clusters = 25\n",
    "kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.c4.xlarge',\n",
    "                output_path='s3://'+ bucket_name +'/titles/',              \n",
    "                k=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kmeans.fit(kmeans.record_set(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1, \n",
    "                                 instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result=kmeans_predictor.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = [r.label['closest_cluster'].float32_tensor.values[0] for r in result]\n",
    "pd.DataFrame(cluster_labels)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.subplots(figsize=(6,3))\n",
    "ax=sns.distplot(cluster_labels, kde=False)\n",
    "title=\"Histogram of Cluster Counts\"\n",
    "ax.set_title(title, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing conclusions from our modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_name='<your_SageMaker_KMeans_job_name_here>'\n",
    "job_name=kmeans._current_job_name\n",
    "\n",
    "model_key = \"titles/\" + job_name + \"/output/model.tar.gz\"\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')\n",
    "\n",
    "Kmeans_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centroids=pd.DataFrame(Kmeans_model_params[0].asnumpy())\n",
    "cluster_centroids.columns=df_titles_transformed.columns\n",
    "cluster_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 6))\n",
    "ax = sns.heatmap(cluster_centroids.T, cmap = 'YlGnBu')\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "ax.set_title(\"Attribute Value by Centroid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles_transformed['labels']=list(map(int, cluster_labels))\n",
    "df_titles_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=df_titles_transformed[df_titles_transformed['labels']==20]\n",
    "cluster.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(pca_predictor.endpoint)\n",
    "sagemaker.Session().delete_endpoint(kmeans_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
